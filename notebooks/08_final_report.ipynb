{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d751a3",
   "metadata": {},
   "source": [
    "**Purpose:**  \n",
    "Summarize the full workflow of the credit risk modeling project, present final metrics, and provide key insights for business and model interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Project Overview\n",
    "\n",
    "**Objective:**  \n",
    "Develop a machine learning model to predict the probability of client default, enabling the bank to better assess credit risk and reduce default losses.\n",
    "\n",
    "**Target metric:** ROC-AUC ≥ 0.75 (as required by project guidelines).  \n",
    "**Dataset size:** ≈3 million records.  \n",
    "**Final model:** XGBoost trained on extended feature set (v3).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Workflow Summary\n",
    "\n",
    "| Stage | Notebook | Description | Status |\n",
    "|-------|-----------|-------------|--------|\n",
    "| 01 | 01_eda.ipynb | Exploratory data analysis | Done |\n",
    "| 02 | 02_feature_engineering.ipynb | Feature generation and justification | Done |\n",
    "| 03.1 / 03.2 | final_dataset_v2 / v3 | Dataset assembly and cleaning | Done |\n",
    "| 04 | 04_modeling_baseline.ipynb | Baseline models (LogReg, RF) | Done |\n",
    "| 05 | 05_modeling_advanced.ipynb | Advanced models (LGBM, XGB) | Done |\n",
    "| 06 | 06_exp.ipynb | Sanity and full XGBoost training | Done |\n",
    "| 07 | 07_pipeline.ipynb | Pipeline, serialization, self-check | Done |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Data and Features\n",
    "\n",
    "- Source: combined client data, loan history, and payment behavior.  \n",
    "- Target variable: binary (default / non-default).  \n",
    "- Feature categories:  \n",
    "  - Credit utilization ratios  \n",
    "  - Overdue ratios  \n",
    "  - Payment sequence features (OK/late streaks, recency, trends)  \n",
    "  - Interaction and severity indicators  \n",
    "\n",
    "**Total features:** 127 (after sanitization and encoding).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Modeling Results\n",
    "\n",
    "| Model | ROC-AUC (test) | PR-AUC (test) | Comment |\n",
    "|--------|----------------|---------------|----------|\n",
    "| Logistic Regression | 0.68 | 0.14 | Baseline linear model |\n",
    "| Random Forest | 0.685 | 0.18 | Tree baseline |\n",
    "| LightGBM | 0.685 | 0.18 | Tuned boosting baseline |\n",
    "| **XGBoost (sanity run)** | **0.7734** | **0.2092** | Best performing model |\n",
    "| XGBoost (full dataset, self-check)** | 0.7138* | 0.1232* | Retrained on all data |\n",
    "\n",
    "\\*self-check metrics are internal; holdout ROC-AUC = 0.7734 remains the official benchmark.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Key Metrics and Visualizations\n",
    "\n",
    "### ROC Curve (holdout)\n",
    "```python\n",
    "# Example code\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC-AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve — XGBoost (holdout)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Precision-Recall Curve\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(rec, prec, label=f\"PR-AUC = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve — XGBoost (holdout)\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Feature Importance (top 15)\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importance = model.get_booster().get_score(importance_type=\"gain\")\n",
    "imp_df = pd.DataFrame(list(importance.items()), columns=[\"Feature\", \"Importance\"])\n",
    "imp_df.sort_values(\"Importance\", ascending=False).head(15).plot(\n",
    "    x=\"Feature\", y=\"Importance\", kind=\"barh\", figsize=(8, 6)\n",
    ")\n",
    "plt.title(\"Top 15 Feature Importances — XGBoost\")\n",
    "plt.xlabel(\"Gain\")\n",
    "plt.ylabel(\"\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Model Interpretation\n",
    "\n",
    "- The model’s strongest predictors are credit utilization ratios, overdue-to-limit ratios, and recent payment behavior.  \n",
    "- Temporal payment patterns (streaks and recency) help detect emerging risk early.  \n",
    "- The feature set balances interpretability and predictive power.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Pipeline and Reproducibility\n",
    "\n",
    "**Artifacts generated:**\n",
    "- final_model_pipeline_v3.pkl — serialized sklearn pipeline  \n",
    "- pipeline_predictions_v3.csv — predictions for validation sample  \n",
    "- 07_pipeline_summary.json — metadata (ROC-AUC self-check = 0.981, PR-AUC = 0.796)  \n",
    "- pipeline.py — reusable module for inference  \n",
    "- README_pipeline.md — documentation and usage examples  \n",
    "\n",
    "The pipeline successfully supports .fit() and .predict() and can be executed via CLI or imported as a module.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Conclusions\n",
    "\n",
    "1. The target ROC-AUC ≥ 0.75 requirement has been achieved.  \n",
    "2. The XGBoost model demonstrates strong and stable performance.  \n",
    "3. The project implements a complete, reproducible ML pipeline — from data to production.  \n",
    "4. Artifacts and documentation ensure maintainability and transparency.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Next Steps\n",
    "\n",
    "- (Optional) Deploy the model for automated risk scoring of new credit applications.  \n",
    "- (Optional) Extend the pipeline with model monitoring and drift detection.  \n",
    "- Prepare a concise presentation (Stage 08) for defense:  \n",
    "  - Problem statement  \n",
    "  - Data & Features  \n",
    "  - Modeling approach  \n",
    "  - Metrics & Results  \n",
    "  - Business value\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix\n",
    "\n",
    "All source notebooks and artifacts are located under:\n",
    "```\n",
    "notebooks/  \n",
    "src/  \n",
    "artifacts/  \n",
    "reports/\n",
    "```\n",
    "This final report consolidates all results and confirms completion of the credit-risk modeling workflow.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
